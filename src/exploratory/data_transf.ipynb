{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52da69f8",
   "metadata": {},
   "source": [
    "# A&E Data Transformation and Preprocessing\n",
    "\n",
    "This notebook contains the data transformation process for the A&E (Accident & Emergency) optimization project for Public Health Scotland.\n",
    "\n",
    "## Required Data\n",
    "\n",
    "For this analysis, we need:\n",
    "- **Hospital locations**: A map of hospitals in Scotalnd\n",
    "- **Patient distribution**: Patient data mapped by postcode/datazone\n",
    "- **Wait times**: Waiting times for each patient\n",
    "- **Accessibility data**: Driving/travel times for each patient to the facilities\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. Load and clean population data\n",
    "2. Process hospital location data\n",
    "3. Analyze A&E activity data\n",
    "4. Merge datasets and create spatial joins\n",
    "5. Visualize population distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba61759",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "We'll use the following libraries:\n",
    "- **pandas**: For data manipulation and analysis\n",
    "- **geopandas**: For spatial data operations\n",
    "- **matplotlib**: For data visualization\n",
    "- **geodatasets**: For accessing geographic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import geodatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd76b846",
   "metadata": {},
   "source": [
    "## 2. Load and Process Population Data\n",
    "\n",
    "In this section, we'll:\n",
    "1. Load the population data from the CSV file\n",
    "2. Filter the data to keep only the relevant information\n",
    "3. Transform the age distribution data to a more usable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0dcf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the population data\n",
    "data_pop = pd.read_csv(\"../../data/dz2011-pop-est_21112024.csv\")\n",
    "data_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85fd4c8",
   "metadata": {},
   "source": [
    "### 2.1 Filter Population Data\n",
    "\n",
    "We need to filter the population dataset to:\n",
    "- Keep only data from the year 2022\n",
    "- Select records with \"All\" sex to get total population\n",
    "- Remove rows with data quality issues (missing DataZoneQF)\n",
    "- Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de88ad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for year 2022, sex \"All\", and no DataZoneQF (good quality data)\n",
    "data_pop = data_pop[\n",
    "    (data_pop.Year == 2022) &\n",
    "    (data_pop.Sex  == \"All\") &\n",
    "    (data_pop.DataZoneQF.isna())\n",
    "].copy()\n",
    "\n",
    "# Remove unnecessary columns: flags, sex, and total population\n",
    "data_pop.drop(columns=[\"DataZoneQF\", \"Sex\", \"SexQF\", \"AllAges\"], inplace=True)\n",
    "\n",
    "print(f\"Number of datazones after filtering: {len(data_pop)}\")\n",
    "data_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1bdeab",
   "metadata": {},
   "source": [
    "### 2.2 Transform Age Data\n",
    "\n",
    "The age data is currently in wide format, with separate columns for each age group. \n",
    "We'll transform it to long format for easier analysis:\n",
    "1. Melt the dataframe to convert age columns to rows\n",
    "2. Convert age values to numeric format\n",
    "3. Handle 90+ ages appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e693880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot age columns into long format\n",
    "age_cols = [c for c in data_pop.columns if c.startswith(\"Age\")]\n",
    "data_pop = data_pop.melt(\n",
    "    id_vars=[c for c in data_pop.columns if c not in age_cols],\n",
    "    value_vars=age_cols,\n",
    "    var_name=\"Age\",\n",
    "    value_name=\"Population\"\n",
    ")\n",
    "\n",
    "# Convert Age to numeric, set 90+ as 90\n",
    "data_pop['Age'] = data_pop['Age'].str.replace('Age', '')\n",
    "data_pop['Age'] = pd.to_numeric(data_pop['Age'], errors='coerce')\n",
    "data_pop['Age'].fillna(90, inplace=True)\n",
    "\n",
    "print(f\"Number of rows after transformation: {len(data_pop)}\")\n",
    "data_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df422c97",
   "metadata": {},
   "source": [
    "### 2.3 Check for Missing Values\n",
    "\n",
    "Let's verify the data quality by checking for missing values in the population dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "print(\"üìä Number of missing values per column:\")\n",
    "print(data_pop.isna().sum())\n",
    "print()\n",
    "\n",
    "# Calculate percentage of missing values\n",
    "print(\"üìâ Percentage of missing values per column:\")\n",
    "print((data_pop.isna().mean() * 100).round(2))\n",
    "print()\n",
    "\n",
    "# Count rows with at least one missing value\n",
    "nan_rows = data_pop.isna().any(axis=1).sum()\n",
    "print(f\"‚ö†Ô∏è Rows with at least one missing value: {nan_rows} out of {len(data_pop)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d2ce3",
   "metadata": {},
   "source": [
    "## 3. Load and Process Hospital Data\n",
    "\n",
    "Now we'll load the hospital dataset containing information about healthcare facilities:\n",
    "1. Load the CSV file with hospital information\n",
    "2. Remove unnecessary address details\n",
    "3. Check data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26138292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hospital data\n",
    "data_hospital = pd.read_csv(\"../../data/hospitals.csv\")\n",
    "\n",
    "# Drop address line columns (not needed for analysis)\n",
    "addr_cols = [c for c in data_hospital.columns if c.startswith(\"AddressLine\")]\n",
    "data_hospital.drop(columns=addr_cols, inplace=True)\n",
    "\n",
    "print(f\"Number of hospitals: {len(data_hospital)}\")\n",
    "data_hospital.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f429709",
   "metadata": {},
   "source": [
    "### 3.1 Check for Missing Values in Hospital Data\n",
    "\n",
    "Let's check the quality of the hospital dataset by examining missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0813f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "print(\"üìä Number of missing values per column:\")\n",
    "print(data_hospital.isna().sum())\n",
    "print()\n",
    "\n",
    "# Calculate percentage of missing values\n",
    "print(\"üìâ Percentage of missing values per column:\")\n",
    "print((data_hospital.isna().mean() * 100).round(2))\n",
    "print()\n",
    "\n",
    "# Count rows with at least one missing value\n",
    "nan_rows = data_hospital.isna().any(axis=1).sum()\n",
    "print(f\"‚ö†Ô∏è Rows with at least one missing value: {nan_rows} out of {len(data_hospital)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e800c",
   "metadata": {},
   "source": [
    "## 4. Load and Clean A&E Activity Data\n",
    "\n",
    "Next, we'll process the A&E activity data:\n",
    "1. Load the monthly activity data\n",
    "2. Filter to keep only the aggregate records (AttendanceCategory = \"All\")\n",
    "3. Remove unnecessary columns like percentages and quality flags\n",
    "4. Prepare the data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48667997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load A&E activity data\n",
    "data_activity = pd.read_csv(\"../../data/monthly_ae_activity_202505.csv\")\n",
    "\n",
    "# Keep only records with AttendanceCategory = \"All\" (aggregate data)\n",
    "data_activity = data_activity[data_activity.AttendanceCategory == \"All\"].copy()\n",
    "\n",
    "# Drop unnecessary columns: attendance category, percentage columns, quality flags\n",
    "to_drop = [c for c in data_activity.columns\n",
    "           if c == 'AttendanceCategory'\n",
    "           or 'Percentage' in c\n",
    "           or c.endswith('QF')]\n",
    "\n",
    "# Add more columns to drop (episode-level data that we don't need)\n",
    "to_drop += [\n",
    "    'NumberOfAttendancesEpisode',\n",
    "    'NumberWithin4HoursEpisode',\n",
    "    'NumberOver4HoursEpisode',\n",
    "    'NumberOver8HoursEpisode',\n",
    "    'NumberOver12HoursEpisode'\n",
    "]\n",
    "\n",
    "# Drop the columns\n",
    "data_activity.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "# Display results\n",
    "print(f\"‚úÖ Remaining rows: {len(data_activity)}\")\n",
    "print(f\"üì¶ Remaining columns: {list(data_activity.columns)}\")\n",
    "data_activity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42cac6e",
   "metadata": {},
   "source": [
    "### 4.1 Check for Missing Values in A&E Activity Data\n",
    "\n",
    "Let's examine the quality of the A&E activity dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccd7eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "print(\"üìä Number of missing values per column:\")\n",
    "print(data_activity.isna().sum())\n",
    "print()\n",
    "\n",
    "# Calculate percentage of missing values\n",
    "print(\"üìâ Percentage of missing values per column:\")\n",
    "print((data_activity.isna().mean() * 100).round(2))\n",
    "print()\n",
    "\n",
    "# Count rows with at least one missing value\n",
    "nan_rows = data_activity.isna().any(axis=1).sum()\n",
    "print(f\"‚ö†Ô∏è Rows with at least one missing value: {nan_rows} out of {len(data_activity)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c40d5f",
   "metadata": {},
   "source": [
    "## A&E Data Processing\n",
    "\n",
    "After examining the missing values, we need to process the A&E activity data to prepare it for our analysis. This involves:\n",
    "\n",
    "1. Converting date columns to the proper datetime format\n",
    "2. Filtering the data by department type (ED or MIU)\n",
    "3. Aggregating metrics by location and time period\n",
    "4. Creating useful derived metrics for our analysis\n",
    "\n",
    "Let's start by handling the date columns and examining the department types in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b7e76",
   "metadata": {},
   "source": [
    "### 4.2 Patient Data Generation\n",
    "\n",
    "In this section, we expand the aggregate A&E data to create individual patient records. This is important for our analysis as it allows us to:\n",
    "\n",
    "1. Model individual waiting times rather than just using aggregates\n",
    "2. Apply different filters and segmentations to the data\n",
    "3. Create more detailed visualizations\n",
    "\n",
    "The process involves:\n",
    "- Converting date columns to proper datetime format\n",
    "- Identifying different department types (ED vs MIU)\n",
    "- Creating synthetic patient records based on the aggregate counts\n",
    "- Assigning reasonable waiting times:\n",
    "  - For patients seen within 4 hours: random time between 1-240 minutes\n",
    "  - For patients seen after 4 hours: random time between 241-720 minutes\n",
    "\n",
    "This synthetic patient-level dataset will enable us to perform more detailed analyses while preserving the statistical properties of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "# Create a copy of the original dataset\n",
    "df = data_activity.copy()\n",
    "\n",
    "# Show available columns\n",
    "print(\"Available columns in data_activity:\")\n",
    "print(df.columns.tolist())\n",
    "print()\n",
    "\n",
    "# Convert Month column to datetime format\n",
    "df[\"Month\"] = pd.to_datetime(df[\"Month\"], format=\"%Y%m\")\n",
    "\n",
    "# Display the unique department types in the dataset\n",
    "print(\"Department types in the dataset:\")\n",
    "print(df[\"DepartmentType\"].unique())\n",
    "print()\n",
    "\n",
    "# Fill any NaN values with 0\n",
    "df[['NumberWithin4HoursAll', 'NumberOver4HoursAll', 'NumberOfAttendancesAll']] = \\\n",
    "    df[['NumberWithin4HoursAll', 'NumberOver4HoursAll', 'NumberOfAttendancesAll']].fillna(0).astype(int)\n",
    "\n",
    "# List to collect expanded patient rows\n",
    "patient_rows = []\n",
    "\n",
    "# Initialize progress bar\n",
    "print(\"‚è≥ Generating individual patient records...\")\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "    total = row['NumberOfAttendancesAll']\n",
    "    n_within = row['NumberWithin4HoursAll']\n",
    "    n_over = row['NumberOver4HoursAll']\n",
    "\n",
    "    # Patients seen within 4 hours\n",
    "    if n_within > 0:\n",
    "        wait_times_within = np.random.uniform(1, 240, size=n_within).astype(int)\n",
    "        for wt in wait_times_within:\n",
    "            new_row = row.drop(['NumberWithin4HoursAll', 'NumberOver4HoursAll', 'NumberOfAttendancesAll']).copy()\n",
    "            new_row['WaitingTime'] = wt\n",
    "            patient_rows.append(new_row)\n",
    "\n",
    "    # Patients seen after 4 hours\n",
    "    if n_over > 0:\n",
    "        wait_times_over = np.random.uniform(241, 720, size=n_over).astype(int)\n",
    "        for wt in wait_times_over:\n",
    "            new_row = row.drop(['NumberWithin4HoursAll', 'NumberOver4HoursAll', 'NumberOfAttendancesAll']).copy()\n",
    "            new_row['WaitingTime'] = wt\n",
    "            patient_rows.append(new_row)\n",
    "\n",
    "# Build the final DataFrame\n",
    "print(\"üì¶ Building the final DataFrame...\")\n",
    "df_patients = pd.DataFrame(patient_rows)\n",
    "\n",
    "# Final feedback\n",
    "print(f\"‚úÖ Generation completed: {len(df_patients):,} total patients.\")\n",
    "df_patients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e682c",
   "metadata": {},
   "source": [
    "## 5. Data Integration\n",
    "\n",
    "Now we need to combine our datasets to create a comprehensive view of the A&E system:\n",
    "\n",
    "1. Merge A&E activity data with hospital information\n",
    "2. Check for any missing matches (facilities that don't appear in both datasets)\n",
    "3. Prepare the data for spatial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge A&E activity data with hospital information\n",
    "merged_data = pd.merge(\n",
    "    data_activity,\n",
    "    data_hospital,\n",
    "    left_on=\"TreatmentLocation\",\n",
    "    right_on=\"HospitalCode\",\n",
    "    how=\"left\"\n",
    ")\n",
    "print(f\"‚úÖ Number of records after merging: {len(merged_data)}\")\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5ab02",
   "metadata": {},
   "source": [
    "### 5.1 Check for Missing Values in Merged Data\n",
    "\n",
    "After merging the datasets, we need to check for missing values to ensure data quality. This helps us identify:\n",
    "- A&E facilities that might be missing from our hospital dataset\n",
    "- Missing location information that could affect our spatial analysis\n",
    "- Other potential data quality issues that need addressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "print(\"üìä Number of missing values per column:\")\n",
    "print(merged_data.isna().sum())\n",
    "print()\n",
    "\n",
    "# Calculate percentage of missing values\n",
    "print(\"üìâ Percentage of missing values per column:\")\n",
    "print((merged_data.isna().mean() * 100).round(2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aaf90e",
   "metadata": {},
   "source": [
    "## 6. A&E Performance Analysis\n",
    "\n",
    "Now let's analyze the performance of each A&E facility based on our synthetic patient dataset. We'll:\n",
    "\n",
    "1. Group data by treatment location\n",
    "2. Calculate key performance metrics:\n",
    "   - Total number of patients\n",
    "   - Average waiting time (in minutes)\n",
    "   - Median waiting time (in minutes)\n",
    "   - Maximum waiting time (in minutes)\n",
    "   - Percentage of patients seen within 4 hours (the NHS target)\n",
    "3. Sort facilities by their average wait time to identify best and worst performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e8088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by location and calculate metrics\n",
    "location_summary = df_patients.groupby('TreatmentLocation').agg(\n",
    "    total_patients=('WaitingTime', 'count'),\n",
    "    avg_wait_mins=('WaitingTime', 'mean'),\n",
    "    median_wait_mins=('WaitingTime', 'median'),\n",
    "    max_wait_mins=('WaitingTime', 'max'),\n",
    "    pct_within_4h=('WaitingTime', lambda x: (x <= 240).mean() * 100)\n",
    ").reset_index()\n",
    "\n",
    "# Sort by average wait time\n",
    "location_summary = location_summary.sort_values('avg_wait_mins')\n",
    "\n",
    "print(f\"Summary statistics for {len(location_summary)} facilities:\")\n",
    "location_summary.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3174bf",
   "metadata": {},
   "source": [
    "### 6.1 Department Type Comparison\n",
    "\n",
    "A key aspect of our analysis is understanding the difference in performance between Emergency Departments (ED) and Minor Injury Units (MIU). This comparison helps us:\n",
    "\n",
    "1. Identify which type of facility provides faster service\n",
    "2. Understand the patient distribution between facility types\n",
    "3. Evaluate performance against the 4-hour target for each facility type\n",
    "\n",
    "Emergency Departments typically handle more severe cases, while Minor Injury Units focus on less critical injuries. We expect to see different patterns in waiting times between these facility types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter patient data for specific department types\n",
    "ed_patients = df_patients[df_patients.department_type == 'Emergency Department'].copy()\n",
    "miu_patients = df_patients[df_patients.department_type == 'Minor Injury Unit'].copy()\n",
    "\n",
    "# Compare performance between department types\n",
    "dept_comparison = pd.DataFrame({\n",
    "    'Department Type': ['Emergency Department', 'Minor Injury Unit'],\n",
    "    'Number of Patients': [len(ed_patients), len(miu_patients)],\n",
    "    'Avg Wait (mins)': [ed_patients.WaitingTime.mean(), miu_patients.WaitingTime.mean()],\n",
    "    'Median Wait (mins)': [ed_patients.WaitingTime.median(), miu_patients.WaitingTime.median()],\n",
    "    '% Within 4h': [(ed_patients.WaitingTime <= 240).mean() * 100, \n",
    "                    (miu_patients.WaitingTime <= 240).mean() * 100]\n",
    "})\n",
    "\n",
    "print(\"Comparison of department types:\")\n",
    "dept_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9d7551",
   "metadata": {},
   "source": [
    "## 7. Time Series Analysis\n",
    "\n",
    "Understanding how A&E performance changes over time is critical for identifying:\n",
    "- Seasonal patterns in patient volumes\n",
    "- Trends in waiting times\n",
    "- Changes in performance against the 4-hour target\n",
    "\n",
    "Let's create a time series analysis of our synthetic patient data to identify these patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e9240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series of average wait times by month\n",
    "monthly_trend = df_patients.groupby(pd.Grouper(key='month', freq='M')).agg(\n",
    "    avg_wait=('WaitingTime', 'mean'),\n",
    "    median_wait=('WaitingTime', 'median'),\n",
    "    pct_within_4h=('WaitingTime', lambda x: (x <= 240).mean() * 100),\n",
    "    num_patients=('WaitingTime', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"Monthly trends over {len(monthly_trend)} months:\")\n",
    "monthly_trend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f52260",
   "metadata": {},
   "source": [
    "### 7.1 Visualizing Monthly Trends\n",
    "\n",
    "Let's create visualizations to better understand how A&E performance varies over time:\n",
    "\n",
    "1. **Top Chart**: Shows average and median wait times compared to the 4-hour target\n",
    "2. **Bottom Chart**: Displays the percentage of patients seen within 4 hours compared to the NHS 95% target\n",
    "\n",
    "These visualizations help identify:\n",
    "- Seasonal patterns (e.g., winter pressures on A&E services)\n",
    "- Overall trends in performance\n",
    "- Periods where performance is significantly below target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3834f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure for visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot average wait time over time\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(monthly_trend['month'], monthly_trend['avg_wait'], 'b-', label='Average Wait Time')\n",
    "plt.plot(monthly_trend['month'], monthly_trend['median_wait'], 'g--', label='Median Wait Time')\n",
    "plt.axhline(y=240, color='r', linestyle='--', label='4-Hour Target')\n",
    "plt.title('Monthly Average and Median Wait Times', fontsize=14)\n",
    "plt.ylabel('Time (minutes)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot percentage meeting 4-hour target over time\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(monthly_trend['month'], monthly_trend['pct_within_4h'], 'g-')\n",
    "plt.fill_between(monthly_trend['month'], monthly_trend['pct_within_4h'], alpha=0.2, color='g')\n",
    "plt.title('Percentage of Patients Seen Within 4 Hours', fontsize=14)\n",
    "plt.ylabel('Percentage')\n",
    "plt.axhline(y=95, color='r', linestyle='--', label='95% Target')\n",
    "plt.legend(['% Within 4h', '95% Target'])\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../results/images_dir/monthly_performance_trends.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40105266",
   "metadata": {},
   "source": [
    "## 8. Spatial Analysis\n",
    "\n",
    "To understand the geographic distribution of healthcare facilities and identify potential areas for improvement, we need to perform spatial analysis:\n",
    "\n",
    "1. Create a GeoDataFrame from our hospital data\n",
    "2. Visualize facility locations on a map\n",
    "3. Analyze the spatial distribution of wait times and performance\n",
    "\n",
    "This spatial component will help us identify:\n",
    "- Areas with limited A&E access\n",
    "- Geographic patterns in wait times\n",
    "- Potential locations for new facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf64e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GeoDataFrame from hospital data with coordinates\n",
    "gdf_hospitals = gpd.GeoDataFrame(\n",
    "    data_hospital,\n",
    "    geometry=gpd.points_from_xy(data_hospital.Longitude, data_hospital.Latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Preview the GeoDataFrame\n",
    "print(f\"Created GeoDataFrame with {len(gdf_hospitals)} hospital locations\")\n",
    "gdf_hospitals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ba831",
   "metadata": {},
   "source": [
    "### 8.1 Combining Performance Data with Geographic Information\n",
    "\n",
    "To create meaningful spatial visualizations, we need to join our performance metrics with the geographic hospital data:\n",
    "\n",
    "1. Merge the location summary with hospital GeoDataFrame\n",
    "2. Handle missing values for facilities without activity data\n",
    "3. Prepare the data for mapping\n",
    "\n",
    "This allows us to visualize wait times and other metrics across geographic space, helping identify patterns that might not be apparent in tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc34db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join performance metrics to hospital locations\n",
    "gdf_hospitals = gdf_hospitals.merge(\n",
    "    location_summary,\n",
    "    left_on='HospitalCode',\n",
    "    right_on='TreatmentLocation',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values for facilities without activity data\n",
    "gdf_hospitals['total_patients'] = gdf_hospitals['total_patients'].fillna(0)\n",
    "gdf_hospitals['avg_wait_mins'] = gdf_hospitals['avg_wait_mins'].fillna(0)\n",
    "gdf_hospitals['pct_within_4h'] = gdf_hospitals['pct_within_4h'].fillna(0)\n",
    "\n",
    "print(f\"Number of facilities with activity data: {(gdf_hospitals['total_patients'] > 0).sum()}\")\n",
    "print(f\"Number of facilities without activity data: {(gdf_hospitals['total_patients'] == 0).sum()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c40b13",
   "metadata": {},
   "source": [
    "### 8.2 Creating the Final Dataset\n",
    "\n",
    "After analyzing the merged data, we need to create a comprehensive dataset that combines all our data sources:\n",
    "- A&E activity data\n",
    "- Hospital location data\n",
    "- Population data by datazone\n",
    "\n",
    "This final dataset will be used for our spatial analysis and optimization models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5265da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final dataset by joining our datasets\n",
    "# 1. First join merged_data (A&E activity + hospital info) with population data\n",
    "final_data = pd.merge(\n",
    "    merged_data,\n",
    "    data_pop,\n",
    "    on=\"DataZone\",\n",
    "    how=\"right\"  # Use right join as in R's right_join\n",
    ")\n",
    "\n",
    "# 2. Filter for specific months (as done in the R script)\n",
    "# Define the months to include (from 202406 to 202505)\n",
    "year = [\"202406\", \"202407\", \"202408\", \"202409\", \"202410\",\n",
    "        \"202411\", \"202412\", \"202501\", \"202502\", \"202503\",\n",
    "        \"202504\", \"202505\"]\n",
    "\n",
    "# Filter the final data to include only these months\n",
    "final_data = final_data[final_data[\"Month\"].isin(year)]\n",
    "\n",
    "# 3. Save the final dataset to CSV\n",
    "final_data.to_csv(\"../../data/FINAL_DATA.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Final dataset created with {len(final_data)} records\")\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed0a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "print(\"üìä Number of missing values per column:\")\n",
    "print(final_data.isna().sum())\n",
    "print()\n",
    "\n",
    "# Calculate percentage of missing values\n",
    "print(\"üìâ Percentage of missing values per column:\")\n",
    "print((final_data.isna().mean() * 100).round(2))\n",
    "print()\n",
    "\n",
    "# Count rows with at least one missing value\n",
    "nan_rows = final_data.isna().any(axis=1).sum()\n",
    "print(f\"‚ö†Ô∏è Rows with at least one missing value: {nan_rows} out of {len(final_data)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3626f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of the final dataset with key columns\n",
    "print(\"Sample of the final dataset:\")\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6c6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial join with datazone boundaries\n",
    "# Load the shapefile with datazone geometries\n",
    "dz = gpd.read_file(\"../../data/shapefiles/SG_DataZone_Bdry_2011.shp\")\n",
    "\n",
    "# Filter to keep only datazones present in our final dataset\n",
    "selected = dz[dz.DataZone.isin(final_data.DataZone)]\n",
    "\n",
    "# Join the final data with spatial boundaries\n",
    "final_sf = selected.merge(final_data, on=\"DataZone\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa6ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017e5585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map of hospital locations with wait time information\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Get Scotland boundaries for context\n",
    "world = gpd.read_file(geodatasets.get_path('naturalearth.land'))\n",
    "uk = world[world['continent'] == 'Europe']\n",
    "uk.plot(ax=ax, color='lightgray', edgecolor='gray')\n",
    "\n",
    "# Plot hospitals with size proportional to patient volume and color by wait time\n",
    "scatter = gdf_hospitals[gdf_hospitals.total_patients > 0].plot(\n",
    "    ax=ax,\n",
    "    column='avg_wait_mins',\n",
    "    cmap='RdYlGn_r',  # Red (bad) to Green (good)\n",
    "    markersize=gdf_hospitals['total_patients'] / 1000 + 10,\n",
    "    legend=True,\n",
    "    legend_kwds={'label': 'Average Wait Time (mins)'},\n",
    "    edgecolor='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "\n",
    "# Add labels for major facilities\n",
    "for idx, row in gdf_hospitals[gdf_hospitals.total_patients > 50000].iterrows():\n",
    "    plt.annotate(row['OrganisationName'], \n",
    "                 xy=(row.geometry.x, row.geometry.y),\n",
    "                 xytext=(5, 5),\n",
    "                 textcoords=\"offset points\",\n",
    "                 fontsize=8,\n",
    "                 bbox={'facecolor': 'white', 'alpha': 0.8, 'pad': 1})\n",
    "\n",
    "# Add title and customize map\n",
    "plt.title('Hospital Locations with Average A&E Wait Times', fontsize=16)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.axis('equal')\n",
    "\n",
    "# Save the map\n",
    "plt.savefig('../../results/images_dir/hospital_wait_times_map.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc10c28",
   "metadata": {},
   "source": [
    "### 8.2 Creating a Map of A&E Wait Times\n",
    "\n",
    "To visualize the geographic distribution of wait times across Scotland, we'll create a map showing:\n",
    "\n",
    "1. Hospital locations with symbols sized by patient volume\n",
    "2. Color-coded markers representing average wait times (red for longer waits, green for shorter)\n",
    "3. Labels for major facilities handling large patient volumes\n",
    "4. Geographic context using Scotland's boundaries\n",
    "\n",
    "This visualization helps stakeholders quickly identify:\n",
    "- Geographic clusters of high wait times\n",
    "- Areas that might be underserved\n",
    "- Relationships between facility size and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dbcc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average population per data zone\n",
    "geom_data = final_sf.dissolve(\n",
    "    by='DataZone',\n",
    "    aggfunc={'Population': 'mean'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2684199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and ensure correct CRS (coordinate reference system)\n",
    "geom_data = geom_data.reset_index()\n",
    "geom_data = geom_data.set_geometry('geometry')\n",
    "geom_data.crs = dz.crs  # Ensure the coordinate system is correct\n",
    "\n",
    "# Create a map showing average population by data zone\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 14))\n",
    "geom_data.plot(\n",
    "    column='Population',\n",
    "    cmap='viridis',        # Alternative options: 'OrRd', 'plasma', 'YlGnBu', etc.\n",
    "    linewidth=0.1,\n",
    "    edgecolor='gray',\n",
    "    legend=True,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title(\"üìç Average Population per Data Zone (Scotland)\", fontsize=16)\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Save the visualization\n",
    "plt.savefig('../../results/images_dir/population_by_datazone.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce9fe99",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we've:\n",
    "\n",
    "1. **Processed population data** to understand the demographic distribution across data zones\n",
    "2. **Analyzed hospital locations** to map healthcare facilities\n",
    "3. **Transformed A&E activity data** into a synthetic patient-level dataset\n",
    "4. **Calculated key performance metrics** including wait times and 4-hour target compliance\n",
    "5. **Visualized temporal trends** in A&E performance\n",
    "6. **Created spatial visualizations** showing the geographic distribution of wait times\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Based on this exploratory analysis, the next steps for our project include:\n",
    "\n",
    "1. **Develop optimization models** to improve patient allocation across facilities\n",
    "2. **Identify optimal locations** for potential new facilities\n",
    "3. **Simulate changes** to evaluate how modifications might affect waiting times\n",
    "4. **Create an interactive dashboard** for stakeholders to explore scenarios\n",
    "5. **Develop recommendations** for Public Health Scotland to improve A&E performance\n",
    "\n",
    "The results of this analysis provide a foundation for the optimization work in subsequent notebooks and will inform our final recommendations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_phs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
