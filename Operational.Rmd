---
title: "Operational Research for Hospital Sites"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r, echo=FALSE, warning = FALSE, message = FALSE}
library(readxl)
library(tidyverse)
library(magrittr)


setwd("~/Desktop/Operational Research EDI")
data <- read_excel("OR_AE2_Project_Adjusted.xlsx")

data$Number_Of_Attendances <- as.numeric(data$Number_Of_Attendances)
repetitions <- data$Number_Of_Attendances

data <- data[rep(seq_len(nrow(data)), repetitions), -19]

data$Site_Code <- as.factor(data$Site_Code)
data$Site_Type <- as.factor(data$Site_Type)


n_miles <- table(data$Drive_Distance_Miles)

set.seed(1)

data$Drive_Distance_Miles[data$Drive_Distance_Miles == "00 to 05"] <- runif(n_miles[1],0,5)
data$Drive_Distance_Miles[data$Drive_Distance_Miles == "05 to 10"] <- runif(n_miles[2],5,10)
data$Drive_Distance_Miles[data$Drive_Distance_Miles == "10 to 15"] <- runif(n_miles[3],10,15)
data$Drive_Distance_Miles[data$Drive_Distance_Miles == "15 to 20"] <- runif(n_miles[4],15,20)
data$Drive_Distance_Miles[data$Drive_Distance_Miles == "20 to 25"] <- runif(n_miles[5],20,25)
data$Drive_Distance_Miles[data$Drive_Distance_Miles == "25 to 30"] <- runif(n_miles[6],25,30)
data$Drive_Distance_Miles[data$Drive_Distance_Miles == "30 to 35"] <- runif(n_miles[7],30,35)
data$Drive_Distance_Miles[data$Drive_Distance_Miles == "35 to 40"] <- runif(n_miles[8],35,40)
data$Drive_Distance_Miles[data$Drive_Distance_Miles == "40 to 45"] <- runif(n_miles[9],40,45)
data$Drive_Distance_Miles[data$Drive_Distance_Miles == "45 to 50"] <- runif(n_miles[10],45,50)
data$Drive_Distance_Miles[data$Drive_Distance_Miles == "50 to 55"] <- runif(n_miles[11],50,55)

n_mins <- table(data$Driving_Time_mins)

data$Driving_Time_mins[data$Driving_Time_mins == "00 to 05"] <- runif(n_mins[1],0,5)
data$Driving_Time_mins[data$Driving_Time_mins == "05 to 10"] <- runif(n_mins[2],5,10)
data$Driving_Time_mins[data$Driving_Time_mins == "10 to 15"] <- runif(n_mins[3],10,15)
data$Driving_Time_mins[data$Driving_Time_mins == "15 to 20"] <- runif(n_mins[4],15,20)
data$Driving_Time_mins[data$Driving_Time_mins == "20 to 25"] <- runif(n_mins[5],20,25)
data$Driving_Time_mins[data$Driving_Time_mins == "25 to 30"] <- runif(n_mins[6],25,30)
data$Driving_Time_mins[data$Driving_Time_mins == "30 to 35"] <- runif(n_mins[7],30,35)
data$Driving_Time_mins[data$Driving_Time_mins == "35 to 40"] <- runif(n_mins[8],35,40)
data$Driving_Time_mins[data$Driving_Time_mins == "40 to 45"] <- runif(n_mins[9],40,45)
data$Driving_Time_mins[data$Driving_Time_mins == "45 to 50"] <- runif(n_mins[10],45,50)
data$Driving_Time_mins[data$Driving_Time_mins == "50 to 55"] <- runif(n_mins[11],50,55)
data$Driving_Time_mins[data$Driving_Time_mins == "55 to 60"] <- runif(n_mins[12],55,60)
data$Driving_Time_mins[data$Driving_Time_mins == "60 to 65"] <- runif(n_mins[13],60,65)
data$Driving_Time_mins[data$Driving_Time_mins == "65 to 70"] <- runif(n_mins[14],65,70)
data$Driving_Time_mins[data$Driving_Time_mins == "70 to 75"] <- runif(n_mins[15],70,75)
data$Driving_Time_mins[data$Driving_Time_mins == "75 to 80"] <- runif(n_mins[16],75,80)
data$Driving_Time_mins[data$Driving_Time_mins == "80 to 85"] <- runif(n_mins[17],80,85)
data$Driving_Time_mins[data$Driving_Time_mins == "85 to 90"] <- runif(n_mins[18],85,90)

n_age <- table(data$Age_Group)

data$Age_Group[data$Age_Group == "20-39"] <- runif(n_age[1],20,39)
data$Age_Group[data$Age_Group == "40-59"] <- runif(n_age[2], 40,59)
data$Age_Group[data$Age_Group == "60-79"] <- runif(n_age[3],60,79)
data$Age_Group[data$Age_Group == "80+"] <- 80 + rchisq(n_age[4], 5)
data$Age_Group[data$Age_Group == "Missing"] <- NA

data$Year <- factor(data$Year, ordered = T)
data$Month <- factor(data$Month, ordered = T)

n_wait <- table(data$Wait_Time)

data$Wait_Time[data$Wait_Time == "00-29"] <- runif(n_wait[1],0,29)
data$Wait_Time[data$Wait_Time == "120-149"] <- runif(n_wait[2],120,149)
data$Wait_Time[data$Wait_Time == "150-179"] <- runif(n_wait[3],150,179)
data$Wait_Time[data$Wait_Time == "180-209"] <- runif(n_wait[4],180,209)
data$Wait_Time[data$Wait_Time == "210-239"] <- runif(n_wait[5],210,239)
data$Wait_Time[data$Wait_Time == "240-269"] <- runif(n_wait[6],240,269)
data$Wait_Time[data$Wait_Time == "270-299"] <- runif(n_wait[7],270,299)
data$Wait_Time[data$Wait_Time == "30-59"] <- runif(n_wait[8],30,59)
data$Wait_Time[data$Wait_Time == "300-329"] <- runif(n_wait[9],300,359)
data$Wait_Time[data$Wait_Time == "360+"] <- 360 + rchisq(n_age[4], 5)
data$Wait_Time[data$Wait_Time == "60-89"] <- runif(n_wait[11],60,89)
data$Wait_Time[data$Wait_Time == "90-119"] <- runif(n_wait[12],90,119)

data$Wait_Time <- as.numeric(data$Wait_Time)
data$Drive_Distance_Miles <- as.numeric(data$Drive_Distance_Miles)
data$Driving_Time_mins <- as.numeric(data$Driving_Time_mins)
data$Age_Group <- as.numeric(data$Age_Group)
data$Attendance_Type <- as.factor(data$Attendance_Type)

ggplot(data, aes(x = Wait_Time))+
  geom_histogram() # The un-uniform structure is due to the mistake in 
# the data collection, no data between 329 and 360

data <- data %>% mutate(Sum_Time = Driving_Time_mins + Wait_Time)


# Grouping the data and summarizing it
data.p <- data %>% group_by(Site_Code, Month, Year,
                            Site_Type, Site_Loc_GPs,
                            Site_Loc_GP_List, Site_Pop_20miles) %>%
  summarise(n = n(), .groups = "keep")

data.p$n <- as.numeric(data.p$n)
data.p$Site_Code <- as.factor(data.p$Site_Code)
data.p$Month <- as.factor(data.p$Month)
data.p$Year <- as.factor(data.p$Year)
```

## Linear Mixed model

#### to analyze the variation of attendees by Site_Code, Month, and Year

```{r, warning=FALSE, message = FALSE}
library(lme4)
model.p <- lmer(n ~ Site_Code + (1|Month) + (1|Year), data = data.p)
summary(model.p)
```

# Objective 1:

## Predicting the likelihood of a patient visiting a site using Random Forest

# Random Forest Classification Model

```{r,include = FALSE, warning=FALSE, message = FALSE}
set.seed(1)
train.index <- sample.int(nrow(data), 0.7 * nrow(data))
train <- data[train.index,]
test <- data[setdiff(1:nrow(data), train.index),]

library(ranger)
# Load pre-trained model
load("modelRf.Rdata")
predictions <- predict(model_rf, data = test[,-1])
```

#### Confusion matrix to evaluate the model

```{r,echo = FALSE, warning=FALSE, message = FALSE}

library(caret) 
predict_values <- factor(predictions$predictions, levels = levels(test$Site_Code))

actual_values <- factor(test$Site_Code) 

conf_matrix <- confusionMatrix(predict_values, actual_values)

print(conf_matrix)
```

# Objective 2:

## Predicting Number of Patients Using Regression

### Creating a regression model based on distance, site type, month, and year

```{r, warning=FALSE, message = FALSE}
data.p <- data %>% group_by(Site_Code, Month, Year,
                            Site_Type, Pat_X, Pat_Y, Site_X, Site_Y) %>%
  summarise(n = n(), .groups = "keep")
```

##### Calculating the distance between patients and the site

```{r, warning=FALSE, message = FALSE}
data.p <- data.p %>% mutate(Distance = sqrt((Pat_X - Site_X)^2 + (Pat_Y - Site_Y)^2))
```

# Random Forest Model

```{r, warning=FALSE, message = FALSE}
set.seed(1)
trainp.index <- sample.int(nrow(data.p), 0.6 * nrow(data.p))
trainp <- data.p[trainp.index,]
testp <- data.p[setdiff(1:nrow(data.p), trainp.index),]

model_n <- ranger(n ~ Distance + Site_Type + Month + Year, data = trainp, importance = "impurity")
```

```{r, echo = FALSE, warning=FALSE, message = FALSE}
predictions <- predict(model_n, data = testp[,-9])$predictions

predict_values <- predictions
actual_values <- testp[,9]
df <- data.frame(Predictions = predict_values, Actual = actual_values)

plot(df[,1], df[,2], main = "Prediction Regression for Diagnostics of RF")

```

```{r, include = FALSE, warning=FALSE, message = FALSE}
importance_values <- model_n$variable.importance
importance_df <- data.frame(Variable = names(importance_values), Importance = importance_values)
importance_df <- importance_df[order(importance_df$Importance, decreasing = TRUE), ]
```

### Plotting feature importance

```{r, echo= FALSE, warning=FALSE, message = FALSE}
ggplot(importance_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +
  labs(title = "Feature Importance", x = "Variable", y = "Importance") +
  theme_minimal()
```

## Trying Coordinates for new site (from heuristic method)

### Coordinates for new site

```{r, include= TRUE, warning=FALSE, message = FALSE}
coord.new <- c(10640.01507538, 105690.53768844)
```

```{r, include= FALSE, warning=FALSE, message = FALSE}
unique_patients <- unique(data.p[, c("Pat_X", "Pat_Y")])
unique_time <- expand.grid(Month = unique(data.p$Month), Year = unique(data.p$Year))

# Create new site data
new_site <- merge(unique_patients, unique_time)
new_site <- cbind(new_site, Site_Code = "12", Site_X = coord.new[1], Site_Y = coord.new[2], Site_Type = "ED")
new_site <- new_site %>% mutate(Distance = sqrt((Pat_X - Site_X)^2 + (Pat_Y - Site_Y)^2), n = 0)

# Predict number of attendees for the new site
new_site$n <- predict(model_n, data = new_site)$predictions

# Compute the total redistribution
total_new_site <- sum(new_site$n)
total <- sum(data.p$n)
to.redistribute <- total - total_new_site
data.p <- data.p %>% mutate(new_n = n / total * to.redistribute, diff = new_n - n)
```

### Visualize impact

```{r, echo= FALSE, warning=FALSE, message = FALSE}
impact_summary <- data.p %>%
  group_by(Site_Code) %>%
  summarise(diff = sum(diff), percentage_diff = diff / n())
impact <- sum(impact_summary$diff) / total
cat("Total Percentage Reduction of attendance to other sites:", impact)


ggplot(impact_summary, aes(x = Site_Code, y = percentage_diff, fill = percentage_diff > 0)) +
  geom_bar(stat = "identity") +
  labs(title = "Change in Attendance After Adding New Site", x = "Site Code", y = "Change in Attendance")
```

# Optimization Random Forest

## Optimizing the location of a new site using optimization techniques and evaluating its impact

```{r, echo= FALSE, warning=FALSE, message = FALSE}

evaluate_new_site_rf <- function(new_site_coords, data = data.p, model = model_n, total_patients = total_patients){
  new_x <- new_site_coords[1]
  new_y <- new_site_coords[2]
  
  unique_patients <- unique(data[, c("Pat_X", "Pat_Y")])
  unique_time <- expand.grid(
    Month = unique(data$Month),
    Year = unique(data$Year)
  )
  new_site <- merge(unique_patients, unique_time)
  new_site <- cbind(new_site,
                    Site_Code = "12",
                    Site_X = new_x,
                    Site_Y = new_y,
                    Site_Type = "ED" 
  )
  
  new_site <- new_site %>% mutate(
    Distance = sqrt((Pat_X - Site_X)^2 + (Pat_Y - Site_Y)^2),
    n = 0
  )
  
  new_site$n <- predict(model, data = new_site)$predictions
  
  total_new_site <- sum(new_site$n)
  total <- sum(data.p$n)
  to.redistribute <- total - total_new_site
  
  # Step 3: Analyze the impact of adding the new site
  data.p <- data.p %>%
    mutate(new_n = n / total * to.redistribute, #This is a proportional approach
           # so the percentage removed from each of the site is constant
           # no matter the new site location. The only thing changing
           # is the magnitude
           diff = new_n-n) 
  
  
  ## Compute Impact insights
  impact_summary <- data.p %>%
    group_by(Site_Code) %>%
    summarise(diff = sum(diff), percentage_diff = diff/n())
  impact <- sum(impact_summary$diff) / total

  return(impact)
}



library(optimx)

# Define the objective function for optimization
objective_function <- function(coords, data, model, total_patients) {
  impact <- evaluate_new_site_rf(new_site_coords = coords, data = data, model = model, total_patients = total_patients)
  return(abs(impact))  # Maximize absolute value
}

# Define bounds for the search 
x_bounds <- c(min(data.p$Pat_X), max(data.p$Pat_X))
y_bounds <- c(min(data.p$Pat_Y), max(data.p$Pat_Y))

# Optimize new site coordinates
optimal_continuous <- optim(par = c(mean(x_bounds), mean(y_bounds)),  
                             fn = function(coords) -objective_function(coords, data.p, model_n, total_patients),
                             method = "L-BFGS-B",
                             lower = c(x_bounds[1], y_bounds[1]),
                             upper = c(x_bounds[2], y_bounds[2]))

optimal_coords_rf <- data.frame(Site_X = optimal_continuous$par[1], Site_Y = optimal_continuous$par[2])
optimal_impact_rf <- -optimal_continuous$value

# Visualize the optimal new site location
ggplot(data.p) +
  geom_point(aes(x = Site_X, y = Site_Y), col = "darkgreen", size = 2) +
  geom_point(aes(x = Pat_X, y = Pat_Y), col = "black", alpha = 0.6) +
  geom_point(data = optimal_coords_rf, aes(x = Site_X, y = Site_Y), col = "red", size = 3)
```

# Generalized Additive Model (GAM) for Prediction

### Using a Generalized Additive Model (GAM) to predict number of patients

```{r, include = FALSE, warning=FALSE, message = FALSE}
library(gam)
library(mgcv)

model_gam <- gam(n ~ s(Distance) + Site_Type + Month + Year, data = trainp, family = Gamma(link = "log"))
summary(model_gam)
predictions <- predict(model_gam, newdata = testp[,-9])
```

### Evaluate and plot predictions

```{r, echo= FALSE, warning=FALSE, message = FALSE}
df <- data.frame(Predictions = predictions, Actual = testp[,9])
plot(df[,1], df[,2])
```

## Trying Coordinates for new site (from heuristic method)

```{r, echo= FALSE, warning=FALSE, message = FALSE}
# Get unique patient locations
unique_patients <- unique(data.p[, c("Pat_X", "Pat_Y")])

# Get unique combinations of Month and Year
unique_time <- expand.grid(
  Month = unique(data.p$Month),
  Year = unique(data.p$Year)
)

# Combine patient locations with time combinations
new_site <- merge(unique_patients, unique_time)

new_site <- cbind(new_site,
                  Site_Code = "12",
                  Site_X = coord.new[1],
                  Site_Y = coord.new[2],
                  Site_Type = "ED"
)

new_site <- new_site %>% mutate(Distance = sqrt((Pat_X - Site_X)^2 + (Pat_Y - Site_Y)^2),
                                n = 0)

new_site$n <- predict(model_gam, newdata = new_site, type = "response")

total_new_site <- sum(new_site$n)
total <- sum(data.p$n)
to.redistribute <- total - total_new_site

# Step 3: Analyze the impact of adding the new site
data.p <- data.p %>%
  mutate(new_n = n / total * to.redistribute,
         diff = new_n-n) 

# Proportionally remove patients from other sites (this could be done in other
# ways depending on distance)
```

### Visualize impact

```{r, echo= FALSE, warning=FALSE, message = FALSE}

# Summarize the results
# Compare original `n` with adjusted `n`
impact_summary <- data.p %>%
  group_by(Site_Code) %>%
  summarise(diff = sum(diff), percentage_diff = diff/n())
impact <- sum(impact_summary$diff) / total
cat("Total Percentage Reduction of attendance to other sites:", impact)

ggplot(impact_summary, aes(x = Site_Code, y = percentage_diff, fill = percentage_diff > 0)) +
  geom_bar(stat = "identity") +
  labs(title = "Change in Attendance After Adding New Site", x = "Site Code", y = "Change in Attendance")
```

# Optimization GAM

## Optimizing the location of a new site using optimization techniques and evaluating its impact

```{r, warning=FALSE, message = FALSE}

evaluate_new_site_gam <- function(new_site_coords, data = data.p, total_patients = total_patients){
  new_x <- new_site_coords[1]
  new_y <- new_site_coords[2]
  
  unique_patients <- unique(data[, c("Pat_X", "Pat_Y")])
  unique_time <- expand.grid(
    Month = unique(data$Month),
    Year = unique(data$Year)
  )
  new_site <- merge(unique_patients, unique_time)
  new_site <- cbind(new_site,
                    Site_Code = "12",
                    Site_X = new_x,
                    Site_Y = new_y,
                    Site_Type = "ED" 
  )
  
  new_site <- new_site %>% mutate(
    Distance = sqrt((Pat_X - Site_X)^2 + (Pat_Y - Site_Y)^2),
    n = 0
  )
  
  new_site$n <- predict(model_gam, newdata = new_site, type = "response")
  
  total_new_site <- sum(new_site$n)
  total <- sum(data.p$n)
  to.redistribute <- total - total_new_site
  
  # Step 3: Analyze the impact of adding the new site
  data.p <- data.p %>%
    mutate(new_n = n / total * to.redistribute, #This is a proportional approach
           # so the percentage removed from each of the site is constant
           # no matter the new site location. The only thing changing
           # is the magnitude
           diff = new_n-n) 
  
  
  ## Compute Impact insights
  impact_summary <- data.p %>%
    group_by(Site_Code) %>%
    summarise(diff = sum(diff), percentage_diff = diff/n())
  impact <- sum(impact_summary$diff) / total
  
  return(impact)
}

# Define bounds for the search 
x_bounds <- c(min(data.p$Pat_X), max(data.p$Pat_X))
y_bounds <- c(min(data.p$Pat_Y), max(data.p$Pat_Y))


objective_function <- function(coords, data, model, total_patients) {
  impact <- evaluate_new_site_gam(
    new_site_coords = coords,
    data = data,
    total_patients = total_patients
  )
  # Change this for maximization/minimization
  return(abs(impact))  # Maximize absolute value
}

optimal_continuous <- optim(
  par = c(mean(x_bounds), mean(y_bounds)),  
  fn = function(coords) -objective_function(coords, data.p, total_patients),  # Negative for maximization
  method = "L-BFGS-B",
  lower = c(x_bounds[1], y_bounds[1]),
  upper = c(x_bounds[2], y_bounds[2])
)

optimal_coords_gam <- data.frame(Site_X = optimal_continuous$par[1], Site_Y = optimal_continuous$par[2])
optimal_impact_gam <- -optimal_continuous$value  

list(coords = optimal_coords_gam, impact = optimal_impact_gam)

ggplot(data.p)+
  geom_point(aes(x = Site_X, y = Site_Y), col = "darkgreen", size = 2)+
  geom_point(aes(x = Pat_X, y = Pat_Y), col = "black", alpha =0.6)+
  geom_point(data = optimal_coords_gam, aes(x = Site_X, y = Site_Y), col = "red", size = 3)
```

# Poisson Count Model

```{r, include=FALSE, warning = FALSE, message=FALSE}
## Poisson data ###

# Data Preparation
data.p$Month <- as.factor(data.p$Month)
data.p$Year <- as.factor(data.p$Year)
data.p$Site_Type <- as.factor(data.p$Site_Type)
```

```{r, warning = FALSE, message= FALSE}
# Poisson regression is used because `n` is a count variable
model.glm <- glm(n ~ Site_Type + Month + Year + Distance, 
             data = data.p, 
             family = poisson(link = "log"))
# Summarize the model
summary(model.glm)
```

## Trying Coordinates for new site (from heuristic method)

```{r, include =FALSE, warning = FALSE, message= FALSE}
# Step 2: 
coord.new <- c(10640.01507538, 105690.53768844)

# Calculate distances between patients and the new site
unique_patients <- unique(data.p[, c("Pat_X", "Pat_Y")])
unique_time <- expand.grid(
  Month = unique(data$Month),
  Year = unique(data$Year)
)
new_site <- merge(unique_patients, unique_time)
new_site <- cbind(new_site,
                  Site_Code = "12",
                  Site_X = coord.new[1],
                  Site_Y = coord.new[2],
                  Site_Type = "ED" 
)

new_site <- new_site %>% mutate(
  Distance = sqrt((Pat_X - Site_X)^2 + (Pat_Y - Site_Y)^2),
  n = 0
)

# Predict `n` for the new site
new_site$n <- predict(model.glm, newdata = new_site, type = "response")

total_new_site <- sum(new_site$n)
total <- sum(data.p$n)
to.redistribute <- total - total_new_site

# Step 3: Analyze the impact of adding the new site
data.p <- data.p %>%
  mutate(new_n = n / total * to.redistribute,
         diff = new_n-n) 

# Proportionally remove patients from other sites (this could be done in other
# ways depending on distance)

```

Visualize Impact

```{r, echo = FALSE}
# Summarize the results
# Compare original `n` with adjusted `n`
impact_summary <- data.p %>%
  group_by(Site_Code) %>%
  summarise(diff = sum(diff), percentage_diff = diff/n())
impact <- sum(impact_summary$diff) / total
cat("Total Percentage Reduction of attendance to other sites:", impact)

# Visualise
ggplot(impact_summary, aes(x = Site_Code, y = percentage_diff, fill = Site_Code)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Percentage Change in Patient Count After Adding New Site",
    x = "Site Code",
    y = "Percentage Change (%)",
    fill = "Site Code"
  ) 
```

# Optimization Poisson Model

## Optimizing the location of a new site using optimization techniques and evaluating its impact

```{r, warning = FALSE, message = FALSE}
evaluate_new_site_glm <- function(new_site_coords){
  new_x <- new_site_coords[1]
  new_y <- new_site_coords[2]
  
  unique_patients <- unique(data.p[, c("Pat_X", "Pat_Y")])
  unique_time <- expand.grid(
    Month = unique(data.p$Month),
    Year = unique(data.p$Year)
  )
  new_site <- merge(unique_patients, unique_time)
  new_site <- cbind(new_site,
                    Site_Code = "12",
                    Site_X = new_x,
                    Site_Y = new_y,
                    Site_Type = "ED" 
  )
  
  new_site <- new_site %>% mutate(
    Distance = sqrt((Pat_X - Site_X)^2 + (Pat_Y - Site_Y)^2),
    n = 0
  )
  
  new_site$n <- predict(model.glm, newdata = new_site, type = "response")
  
  total_new_site <- sum(new_site$n)
  total <- sum(data.p$n)
  to.redistribute <- total - total_new_site
  
  # Step 3: Analyze the impact of adding the new site
  data.p <- data.p %>%
    mutate(new_n = n / total * to.redistribute,
           diff = new_n-n) 
  
  # Proportionally remove patients from other sites (this could be done in other
  # ways depending on distance)
  
  # Summarize the results
  # Compare original `n` with adjusted `n`
  impact_summary <- data.p %>%
    group_by(Site_Code) %>%
    summarise(diff = sum(diff), percentage_diff = diff/n())
  impact <- sum(impact_summary$diff) / total
  return(impact)
}
# Define bounds for the search 
x_bounds <- c(min(data.p$Pat_X), max(data.p$Pat_X))
y_bounds <- c(min(data.p$Pat_Y), max(data.p$Pat_Y))

objective_function <- function(coords, data, total_patients) {
  impact <- evaluate_new_site_glm(
    new_site_coords = coords
  )
  # Change this for maximization/minimization
  return(abs(impact))  # Maximize absolute value
}

optimal_continuous <- optim(
  par = c(mean(x_bounds), mean(y_bounds)),  
  fn = function(coords) -objective_function(coords),  # Negative for maximization
  method = "L-BFGS-B",
  lower = c(x_bounds[1], y_bounds[1]),
  upper = c(x_bounds[2], y_bounds[2])
)

optimal_coords_glm <- data.frame(Site_X = optimal_continuous$par[1], Site_Y = optimal_continuous$par[2])
optimal_impact_glm <- -optimal_continuous$value  

list(coords = optimal_coords_glm, impact = optimal_impact_glm)

ggplot(data.p)+
  geom_point(aes(x = Site_X, y = Site_Y), col = "darkgreen", size = 2)+
  geom_point(aes(x = Pat_X, y = Pat_Y), col = "black", alpha =0.6)+
  geom_point(data = optimal_coords_glm, aes(x = Site_X, y = Site_Y), col = "red", size = 3)

```

# Final Comparison

```{r, echo =FALSE, warning = FALSE, message = FALSE}

# Combine all optimal coordinates into a single data frame
optimal_coords <- rbind(
  data.frame(Site_X = optimal_coords_glm$Site_X, Site_Y = optimal_coords_glm$Site_Y, Model = "GLM"),
  data.frame(Site_X = optimal_coords_rf$Site_X, Site_Y = optimal_coords_rf$Site_Y, Model = "RF"),
  data.frame(Site_X = optimal_coords_gam$Site_X, Site_Y = optimal_coords_gam$Site_Y, Model = "GAM")
)
print(optimal_coords)

# Main plot showing all patients and sites
main_plot <- ggplot(data.p) +
  # All site locations
  geom_point(aes(x = Site_X, y = Site_Y), col = "darkgreen", size = 2, alpha = 0.8) +
  # All patient locations
  geom_point(aes(x = Pat_X, y = Pat_Y), col = "black", alpha = 0.6) +
  # Optimal coordinates
  geom_point(data = optimal_coords, aes(x = Site_X, y = Site_Y, col = Model), size = 3) +
  # Add labels and title
  labs(
    title = "Patient and Site Locations with Zoomed-In Optimal Coordinates",
    x = "X Coordinate",
    y = "Y Coordinate",
    color = "Model"
  ) +
  theme(
    legend.position = "top",
    plot.title = element_text(hjust = 0.5, face = "bold")
  )

# Zoomed-in plot for optimal coordinates
zoomed_plot <- ggplot(data.p) +
  # All site locations (faint for context)
  geom_point(aes(x = Site_X, y = Site_Y), col = "darkgreen", size = 1, alpha = 0.4) +
  # All patient locations (faint for context)
  geom_point(aes(x = Pat_X, y = Pat_Y), col = "black", alpha = 0.2) +
  # Highlight optimal coordinates
  geom_point(data = optimal_coords, aes(x = Site_X, y = Site_Y, col = Model), size = 4) +
  # Add zoom limits
  coord_cartesian(xlim = c(32000, 34000), ylim = c(105000, 115000)) +
  labs(x = NULL, y = NULL, color = NULL) +
  theme_light() +
  theme(legend.position = "none")  # Hide legend in inset


library(patchwork)

# Add zoomed plot as an inset using patchwork
final_plot <- main_plot +
  inset_element(
    zoomed_plot,
    left = 0.6, right = 0.95, bottom = 0.1, top = 0.5,  # Position the inset
    align_to = "panel"  # Align inset to main panel
  )

# Display the plot
print(final_plot)


```
